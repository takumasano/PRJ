{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp38-none-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.13.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages (from torch) (4.8.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m260.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m240.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2 (from torch)\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m524.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec (from torch)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.3-cp38-cp38-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m515.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp38-none-macosx_11_0_arm64.whl (59.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m47.0/59.5 MB\u001b[0m \u001b[31m116.1 kB/s\u001b[0m eta \u001b[36m0:01:49\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/http/client.py\", line 459, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/http/client.py\", line 503, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/ssl.py\", line 1132, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/tstakuma/anaconda3/envs/VSenv/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import PIL\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "\n",
    "# path\n",
    "path_data = \"/Users/tstakuma/Desktop/anaconda/PRJ/PRJ_task1/samples/sample data/1_19-Oct-2019_10-18-23_mouse.mat\"\n",
    "\n",
    "def expon(x, a):\n",
    "    return a * np.exp(-a*x)\n",
    "\n",
    "\n",
    "def labels2idx(labels, minLen=3):\n",
    "    minCount = 3\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    seqInfor = dict(zip(unique, counts))\n",
    "    seq = {}\n",
    "    for k, v in seqInfor.items():\n",
    "        if v >= minLen:\n",
    "            seq[k] = np.where(labels == k)[0]\n",
    "    return seq\n",
    "\n",
    "\n",
    "def obj2type(x, astype=np.float64):\n",
    "    try:\n",
    "        return x.astype(astype)\n",
    "    except:\n",
    "        return [obj2type(i, astype) for i in x]\n",
    "\n",
    "\n",
    "def findMax(x):\n",
    "    ''' find the max value and its index '''\n",
    "    max_ = np.max(x)\n",
    "    max_idx = np.unravel_index(np.argmax(x, axis=None), x.shape)\n",
    "    return max_, max_idx\n",
    "\n",
    "\n",
    "class ExpInfo:\n",
    "    bad_subj = ['K-Reg-H-1', 'K-Reg-H-2', 'K-Reg-S-5']\n",
    "    taskName = ['one_dot', 'three_dot', 'reaching']\n",
    "    traj_columns_motor = [\"x-shift\", \"y-shift\"]\n",
    "    traj_columns_disp = [['dot-x', 'dot-y'],\n",
    "                         ['dot-x1', 'dot-y1', 'dot-x2',\n",
    "                             'dot-y2', 'dot-x3', 'dot-y3'],\n",
    "                         ['dot-x', 'dot-y']]\n",
    "    screenSize = np.array((1900, 1060))\n",
    "\n",
    "    @staticmethod\n",
    "    def getScreenSise(df):\n",
    "        if 'dot-x1' in df.columns:\n",
    "            screenSize = df.loc[:, 'dot-x1':'dot-y3'].max().max()\n",
    "        else:\n",
    "            screenSize = df.loc[:, 'dot-x':'dot-y'].max().max()\n",
    "        return screenSize\n",
    "\n",
    "    @staticmethod\n",
    "    def getSubjIDs():\n",
    "        files = []\n",
    "        for datapath in path_data_raw:\n",
    "            files += glob.glob(str(datapath) + '/*')\n",
    "\n",
    "        ids = []\n",
    "        for file in files:\n",
    "            id = re.search(r'((K-Reg)|(Reg))-(S|H)-\\d+', file)\n",
    "            if id is not None:\n",
    "                ids.append(id.group())\n",
    "        ids = set(ids).difference(ExpInfo.bad_subj)\n",
    "        ids = list(ids)\n",
    "        ids.sort()\n",
    "        return ids\n",
    "\n",
    "    @staticmethod\n",
    "    def getSubjIDs_byGroup():\n",
    "        ids = ExpInfo.getSubjIDs()\n",
    "        id_H = []\n",
    "        id_S = []\n",
    "        for id in ids:\n",
    "            if 'H' in id:\n",
    "                id_H.append(id)\n",
    "            else:\n",
    "                id_S.append(id)\n",
    "        return id_H, id_S\n",
    "\n",
    "\n",
    "class LoadData:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def mouseMovement(subjID, task, trialno=None):\n",
    "        fname = f'{subjID}_{task}.csv'\n",
    "        fpath = path_data / 'Preprocessing' / 'mouseMovement' / fname\n",
    "        df = pd.read_csv(fpath)\n",
    "        if trialno is not None:\n",
    "            try:\n",
    "                df = df.loc[df['trialno'].isin(trialno)]\n",
    "            except:\n",
    "                try:\n",
    "                    df = df.loc[df['trialno'] == trialno]\n",
    "                except:\n",
    "                    raise ValueError('trialno is not valid')\n",
    "        df = df.loc[df[\"trialno\"] != 0]\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def mouseMovement_array(subj, task, velocity=False, packDot=False):\n",
    "        ''' return array of mouse movement: ([[trial_1], [trial_2]], [[trial_1], [trial_2]])\n",
    "        '''\n",
    "        df = LoadData.mouseMovement(subj, task)\n",
    "        screenSize = ExpInfo.getScreenSise(df)\n",
    "        trials = set(df['trialno'])\n",
    "        xy = []\n",
    "        xy_disp = []\n",
    "        for trial in trials:\n",
    "            df_ = df.query(f'trialno == {trial}').copy()\n",
    "            xy_ = df_[[\"x-shift\", \"y-shift\"]].values / screenSize\n",
    "\n",
    "            if (task == 'one_dot') or (task == 'reaching'):\n",
    "                xy_disp_ = df_[['dot-x', 'dot-y']].values / screenSize\n",
    "            elif task == 'three_dot':\n",
    "                xy_disp_ = df_[['dot-x1', 'dot-y1', 'dot-x2',\n",
    "                                'dot-y2', 'dot-x3', 'dot-y3']].values / screenSize\n",
    "\n",
    "            if velocity:\n",
    "                xy_ = xy_[:-1, :]\n",
    "                xy_disp_ = np.diff(xy_disp_, axis=0)\n",
    "\n",
    "            xy.append(xy_)\n",
    "            \n",
    "            if (task == 'three_dot') and packDot:\n",
    "                xy_disp_ = [xy_disp_[:, 0:2], xy_disp_[:, 2:4], xy_disp_[:, 4:6]]\n",
    "            xy_disp.append(xy_disp_)\n",
    "\n",
    "        return xy, xy_disp\n",
    "\n",
    "    @staticmethod\n",
    "    def mouseMovementRollingData(subjID='K-Reg-S-18', task='one_dot', wSize=48, interval=1, pos=False, nTrial_val=6, seed=0):\n",
    "        # load data\n",
    "        df = LoadData.mouseMovement(subjID, task)\n",
    "\n",
    "        # Split data into train and test\n",
    "        trial_train, trials_val = DataProcessing.split_train_val_trials(\n",
    "            df, nTrial_val=nTrial_val, seed=seed)\n",
    "        df_train = df.query(f'trialno in @trial_train')\n",
    "        df_val = df.query(f'trialno in @trials_val')\n",
    "\n",
    "        # rolling\n",
    "        d_train = DataProcessing.rollingWindow_from_df(\n",
    "            df_train, wSize, interval, pos=pos)\n",
    "        d_val = DataProcessing.rollingWindow_from_df(\n",
    "            df_val, wSize, interval, pos=pos)\n",
    "\n",
    "        class TrajDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, d):\n",
    "                self.d = d\n",
    "\n",
    "            def __len__(self):\n",
    "                return self.d.shape[0]\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                return self.d[idx]\n",
    "\n",
    "        dataset_train = TrajDataset(d_train)\n",
    "        dataset_val = TrajDataset(d_val)\n",
    "        return dataset_train, dataset_val\n",
    "\n",
    "    @staticmethod\n",
    "    def behaviorData(subjID, task):\n",
    "        files = []\n",
    "        for datapath in path_data_raw:\n",
    "            files += list(datapath.glob('*.*'))\n",
    "\n",
    "        for file in files:\n",
    "            if file.match(f'*{subjID}_*{task}_results.csv'):\n",
    "                df = pd.read_csv(file, index_col=False)\n",
    "                df['participant'] = df['participant'].str.strip()\n",
    "                if 'H' in subjID:\n",
    "                    df['group'] = 'H'\n",
    "                else:\n",
    "                    df['group'] = 'S'\n",
    "                return df\n",
    "\n",
    "    @staticmethod\n",
    "    def xhy(subj, task, wSize=60, path='TrajNet_xhy'):\n",
    "        filepath = path_data / path / f'{subj}_{task}_xhy_{wSize}.npz'\n",
    "        d = np.load(filepath, allow_pickle=True)\n",
    "        x, h, y = d['x'], d['h'], d['y']\n",
    "        x = obj2type(x)\n",
    "        h = obj2type(h)\n",
    "        y = obj2type(y)\n",
    "        return x, h, y\n",
    "\n",
    "    @staticmethod\n",
    "    def xhy_disp(subj, task, wSize=60, path='TrajNet_xhy'):\n",
    "        filepath = path_data / path / f'{subj}_{task}_xhy_disp_{wSize}.npz'\n",
    "        d = np.load(filepath, allow_pickle=True)\n",
    "        x, h, y = d['x'], d['h'], d['y']\n",
    "        x, h, y = obj2type(x), obj2type(h), obj2type(y)\n",
    "        return x, h, y\n",
    "\n",
    "\n",
    "class DataProcessing:\n",
    "\n",
    "    @staticmethod\n",
    "    def seqSegmentation(seq, dist_threshold, minLen=3):\n",
    "        from sklearn.cluster import AgglomerativeClustering\n",
    "        connectivity = np.diagflat(np.ones(len(seq)-1), 1)\n",
    "        labels = AgglomerativeClustering(n_clusters=None,\n",
    "                                         distance_threshold=dist_threshold,\n",
    "                                         connectivity=connectivity,\n",
    "                                         linkage='average').fit_predict(seq)\n",
    "        return labels2idx(labels, minLen=minLen)\n",
    "\n",
    "    @staticmethod\n",
    "    def diff(x, measure='euclidean', offset=1):\n",
    "        from scipy.spatial import distance\n",
    "        dist = distance.pdist(x, measure)\n",
    "        dist = distance.squareform(dist)\n",
    "        dist = np.diagonal(dist, offset=offset)\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def split_train_val_trials(df, nTrial_val=6, seed=0):\n",
    "        trials = set(df['trialno']).difference([0])\n",
    "        nTrial = len(trials)\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        rng = np.random.default_rng(seed)\n",
    "        trials_val = rng.choice(nTrial, nTrial_val, replace=False)\n",
    "        trial_train = trials.difference(trials_val)\n",
    "        return trial_train, trials_val\n",
    "\n",
    "    @staticmethod\n",
    "    def rollingWindow(d, wSize=60, interval=1, pos=False):\n",
    "        \"\"\" Rolling window function along time dim\n",
    "        Args:\n",
    "            d (np.array): time x feature\n",
    "            wSize (int): window size\n",
    "            interval (int): interval size\n",
    "\n",
    "        Returns:\n",
    "            np.array: rolling windowed array\n",
    "        \"\"\"\n",
    "        if d.shape[0] < wSize:\n",
    "            raise ValueError('Data length is shorter than window size')\n",
    "        d_ = []\n",
    "        S = 0\n",
    "        E = S + wSize\n",
    "        while E <= (len(d)-1):\n",
    "            d_.append(d[S:E, :])\n",
    "            S += interval\n",
    "            E = S + wSize\n",
    "        d_ = np.stack(d_, axis=0)\n",
    "        if pos:\n",
    "            d_ = d_.cumsum(axis=1)\n",
    "        return d_\n",
    "\n",
    "    @staticmethod\n",
    "    def rollingWindow_from_df(df, wSize, interval=1, pos=False, returnWithTrial=False):\n",
    "        ''' Run rolling window function based on trial number\n",
    "        '''\n",
    "        screensize = ExpInfo.getScreenSise(df)\n",
    "        d = []\n",
    "        trials = list(set(df['trialno']).difference([0]))\n",
    "        for trial in trials:\n",
    "            df_ = df.query(f'trialno == {trial}').copy()\n",
    "            df_ = df_[[\"x-shift\", \"y-shift\"]].values / screensize\n",
    "            d.append(DataProcessing.rollingWindow(\n",
    "                df_, wSize, interval, pos=pos))\n",
    "\n",
    "        if returnWithTrial:\n",
    "            return d\n",
    "        else:\n",
    "            return np.concatenate(d, axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def cart2pol(x, y):\n",
    "        rho = np.sqrt(x**2 + y**2)\n",
    "        phi = np.arctan2(y, x)\n",
    "        return(rho, phi)\n",
    "\n",
    "    @staticmethod\n",
    "    def positionEncoding_sincos_mat(nTime, dim=4, max_length=300):\n",
    "        ''' Position encoding matrix '''\n",
    "        x = np.arange(nTime) * 2 * np.pi / max_length\n",
    "        x = np.tile(x, (dim, 1)).T  # t f\n",
    "        x = x * np.arange(1, dim+1)\n",
    "        x = np.hstack((np.sin(x), np.cos(x)))\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def seqTrim(x, minTime):\n",
    "        ''' Trim the sequence to the minimum timeshift'''\n",
    "        # x: b t f\n",
    "        tLen = np.random.randint(minTime, x.shape[1])\n",
    "        sTime = np.random.randint(0, x.shape[1]-tLen)\n",
    "        eTime = sTime + tLen\n",
    "        return x[:, sTime:eTime, :]\n",
    "\n",
    "    @staticmethod\n",
    "    def standardise_list(xList):\n",
    "        ''' Standardise list of arrays'''\n",
    "        xList_ = np.concatenate(xList, axis=0)\n",
    "        scale = StandardScaler().fit(xList_)\n",
    "        return [scale.transform(x) for x in xList]\n",
    "\n",
    "\n",
    "class SynthData:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def spiral(nTime=72, nBatch=64, seed=0, add_polar=False):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        XY = []\n",
    "        for i in range(nBatch):\n",
    "            theta = np.linspace(rng.uniform(0.5, 2*np.pi*4),\n",
    "                                rng.uniform(0.5, 2*np.pi*4), nTime)\n",
    "            r = np.linspace(rng.uniform(), 1, nTime)\n",
    "            transform = rng.random((2, 2))\n",
    "\n",
    "            def polar2z(r, theta):\n",
    "                compx = r * np.exp(1j * theta)\n",
    "                xy = np.vstack([np.real(compx), np.imag(compx)]).T\n",
    "                return xy\n",
    "\n",
    "            xy = polar2z(r, theta)\n",
    "            if rng.random() > 0.5:\n",
    "                r = -r\n",
    "\n",
    "            xy = polar2z(r, theta)\n",
    "            if rng.random() > 0.5:\n",
    "                xy[:, 0] = -xy[:, 0]\n",
    "\n",
    "            if rng.random() > 0.5:\n",
    "                xy[:, 1] = -xy[:, 1]\n",
    "\n",
    "            xy = np.roll(xy, 1, axis=1)\n",
    "            xy = np.matmul(xy, transform)\n",
    "\n",
    "            xy = xy / np.max(np.abs(xy))\n",
    "            XY.append(xy)\n",
    "        XY = np.stack(XY, 2)\n",
    "        XY = np.transpose(XY, (2, 0, 1))\n",
    "\n",
    "        if add_polar:\n",
    "            x_, y_ = DataProcessing.cart2pol(XY[:, :, 0], XY[:, :, 1])\n",
    "            x_ = repeat(x_, 'b t -> b t f', f=1)\n",
    "            y_ = repeat(y_, 'b t -> b t f', f=1)\n",
    "            XY = np.concatenate([XY, x_, y_], axis=2)\n",
    "        return XY\n",
    "\n",
    "    @staticmethod\n",
    "    def spiral_dataset(**kwargs):\n",
    "        x = SynthData.spiral(**kwargs)\n",
    "        return TensorDataset(torch.from_numpy(x))\n",
    "\n",
    "    @staticmethod\n",
    "    def sin(nTime=72, nBatch=8, plot=False):\n",
    "        data = [np.linspace(0, 2*np.pi, nTime),\n",
    "                np.linspace(np.pi/2, np.pi/2+2*np.pi, nTime)]\n",
    "        data = np.vstack(data).T\n",
    "        data = np.sin(data)\n",
    "        data = np.tile(data, (nBatch, 1, 1))\n",
    "        data = data + np.random.random(data.shape)/2\n",
    "        if plot:\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig, ax = plt.subplots(1)\n",
    "            ax.plot(data[0, :, 1])\n",
    "            ax.plot(data[0, :, 0])\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def genReachingSeq(nReach=10, time=5, fs=60, velocity=True, seed=0):\n",
    "        ''' Generate a sequence of reaching motion '''\n",
    "        # reproducibility \n",
    "        rng = np.random.default_rng(seed)\n",
    "        \n",
    "        # --------------------------- locate target points --------------------------- #\n",
    "        screenSize = ExpInfo.screenSize / (ExpInfo.screenSize.max())\n",
    "        toCentre = screenSize[1]/2 * (4/3)\n",
    "        \n",
    "        # define 4 target points\n",
    "        targetsLocation = np.array([[-toCentre, 0], [toCentre, 0], [0, -toCentre], [0, toCentre]])\n",
    "        \n",
    "        # --------------------------- random select targets -------------------------- #\n",
    "        targetSet = np.arange(4)\n",
    "        iTarget = [rng.choice(targetSet)]\n",
    "        for i in range(1, nReach):\n",
    "            targetSet_ = targetSet\n",
    "            targetSet_ = np.delete(targetSet_, iTarget[-1])\n",
    "            iTarget.append(rng.choice(targetSet_, 1))\n",
    "        iTarget = np.hstack(iTarget)\n",
    "        \n",
    "        # ----------------------- interpolate reaching sequence ---------------------- #\n",
    "        tp = time * fs # number of samples\n",
    "        target = np.vstack([[0, 0], targetsLocation[iTarget]])\n",
    "        itp = np.linspace(0, tp, nReach+1).astype(int)\n",
    "        x = np.interp(np.arange(tp), itp, target[:, 0])\n",
    "        y = np.interp(np.arange(tp), itp, target[:, 1])\n",
    "        if velocity:\n",
    "            x = np.diff(x)\n",
    "            y = np.diff(y)\n",
    "        xy = np.vstack([x, y]).T\n",
    "        return xy, target\n",
    "    \n",
    "    @staticmethod\n",
    "    def genReachingSeq_trial(nTrial, seed=0, **kwargs):\n",
    "        xy = []\n",
    "        target = []\n",
    "        for i in range(nTrial):\n",
    "            xy_, target_ = SynthData.genReachingSeq(seed=i+seed, **kwargs)\n",
    "            xy.append(xy_)\n",
    "            target.append(target_)\n",
    "        return xy, target\n",
    "            \n",
    "\n",
    "\n",
    "class Plot:\n",
    "    palette_group = ['#A96FBD','#6F89BD']\n",
    "\n",
    "    @staticmethod\n",
    "    def traj_withColour(x, y, fig=None, ax=None):\n",
    "        if fig is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        colors = np.linspace(0, 1, len(x))\n",
    "        ax.plot(x, y, '-k', alpha=0.2)\n",
    "        ax.scatter(x, y, c=colors, cmap='turbo')\n",
    "        ax.plot(x[0], y[0], 'Dr', label='start', markersize=8)\n",
    "        ax.axis('equal')\n",
    "        norm = mpl.colors.Normalize(vmin=0, vmax=len(x))\n",
    "        cbar = fig.colorbar(mpl.cm.ScalarMappable(\n",
    "            cmap='turbo', norm=norm), ax=ax)\n",
    "        cbar.set_label('Time step')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.legend()\n",
    "        return fig, ax\n",
    "\n",
    "    @staticmethod\n",
    "    def traj_withWeight(x, y, w, align='e', ax=None, seqColormap='viridis', minSize=10, maxSize=200):\n",
    "        ''' Plot trajectory with weights\n",
    "        align: 'e'(default) end, 's' start, 'c' center\n",
    "        '''\n",
    "        from sklearn.preprocessing import minmax_scale\n",
    "        w = minmax_scale(w, feature_range=(minSize, maxSize))\n",
    "        n = len(x)\n",
    "        nW = len(w)\n",
    "        if align == 's':\n",
    "            offset = 0\n",
    "        elif align == 'e':\n",
    "            offset = n - nW\n",
    "        elif align == 'c':\n",
    "            offset = (n - nW)//2\n",
    "        else:\n",
    "            raise ValueError('align must be e, s, or c')\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "        # plot line\n",
    "        ax.plot(x, y, 'k', alpha=0.3)\n",
    "\n",
    "        # plot sample points with color\n",
    "        cmap = mpl.cm.get_cmap(seqColormap)\n",
    "        colors = cmap(range(n))\n",
    "        # ax.scatter(x, y, c=colors, s=minSize)\n",
    "        ax.scatter(x, y, c='k', s=3, alpha=0.5)\n",
    "\n",
    "        # plot starting point\n",
    "        ax.plot(x[0], y[0], 'dr')\n",
    "\n",
    "        # plot weights\n",
    "        sc = ax.scatter(x[offset:offset+nW], y[offset:offset+nW],\n",
    "                        c=colors[offset:offset+nW, :],\n",
    "                        s=w,\n",
    "                        edgecolors='k',\n",
    "                        alpha=0.8)\n",
    "        ax.axis('equal')\n",
    "        norm = mpl.colors.Normalize(vmin=offset, vmax=offset+nW)\n",
    "        cbar = fig.colorbar(mpl.cm.ScalarMappable(\n",
    "            cmap=seqColormap, norm=norm), ax=ax)\n",
    "        cbar.set_label('Time step')\n",
    "        if ax is None:\n",
    "            return fig, ax\n",
    "\n",
    "    @staticmethod\n",
    "    def traj_withCluster(x, y, labels, align='e', ax=None, seqColormap='viridis', clusterColormap='tab20'):\n",
    "        n = len(x)\n",
    "        nW = len(labels)\n",
    "        if align == 's':\n",
    "            offset = 0\n",
    "        elif align == 'e':\n",
    "            offset = n - nW\n",
    "        elif align == 'c':\n",
    "            offset = (n - nW)//2\n",
    "        else:\n",
    "            raise ValueError('align must be e, s, or c')\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "        # plot line\n",
    "        ax.plot(x, y, 'k', alpha=0.3)\n",
    "\n",
    "        # plot starting point\n",
    "        ax.plot(x[0], y[0], 'dr')\n",
    "\n",
    "        # plot labels\n",
    "        cmap = mpl.cm.get_cmap(clusterColormap)\n",
    "        nCluster = len(set(labels))+1\n",
    "        edgecolors = cmap(labels)\n",
    "        sc = ax.scatter(x[offset:offset+nW], y[offset:offset+nW],\n",
    "                        edgecolors=edgecolors,\n",
    "                        s=200,\n",
    "                        linewidths=2,\n",
    "                        facecolors='none',\n",
    "                        alpha=0.8)\n",
    "\n",
    "        # plot sample points with color\n",
    "        cmap = mpl.cm.get_cmap(seqColormap)\n",
    "        colors = cmap(range(n))\n",
    "        ax.scatter(x, y, c=colors, s=20, alpha=1)\n",
    "        ax.axis('equal')\n",
    "        if ax is None:\n",
    "            return fig, ax\n",
    "\n",
    "    @staticmethod\n",
    "    def fig2img(fig):\n",
    "        fig.canvas.draw()\n",
    "        img = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        img = PIL.Image.fromarray(img)\n",
    "        return img\n",
    "\n",
    "    # ---------------------------------------------------------------------------- #\n",
    "    #                           Plot traj_and_Reconstruc                           #\n",
    "    # ---------------------------------------------------------------------------- #\n",
    "    @staticmethod\n",
    "    def traj_and_Reconstruc_from_batch(x, y, x_full=None, fig=None, nSegment=24, nCol=5, cmap='viridis'):\n",
    "        ''' First order function for plotting trajectory and reconstructed trajectory\n",
    "        '''\n",
    "        nBatch = x.shape[0]\n",
    "        wSize = x.shape[1]\n",
    "        plot_offset = 0\n",
    "\n",
    "        # compute starting points of segments\n",
    "        start_idx = np.linspace(0, nBatch, nSegment + 1).astype(int)[:-1]\n",
    "        nRow = np.ceil((nSegment+1) / nCol).astype(int)\n",
    "\n",
    "        # setup colormap\n",
    "        if x_full is None:\n",
    "            t_len = 301\n",
    "        else:\n",
    "            t_len = x_full.shape[0]\n",
    "        colors = np.linspace(0, 1, t_len)\n",
    "        cmap = mpl.cm.get_cmap(cmap)\n",
    "\n",
    "        # setup figure\n",
    "        if fig is None:\n",
    "            fig = plt.figure(figsize=(4*nRow, 4*nCol))\n",
    "        ax = fig.subplots(nRow, nCol)\n",
    "        if ax.ndim == 1:\n",
    "            ax = ax.reshape(1, -1)\n",
    "\n",
    "        # plot full trajectory\n",
    "        if x_full is not None:\n",
    "            ax[0, 0].plot(x_full[:, 0], x_full[:, 1], '-k', alpha=0.2)\n",
    "            ax[0, 0].scatter(x_full[:, 0], x_full[:, 1], c=colors, cmap=cmap)\n",
    "            ax[0, 0].plot(0, 0, 'Dr', label='start', markersize=8)\n",
    "            ax[0, 0].axis('equal')\n",
    "            plot_offset = 1\n",
    "\n",
    "        for i, si in enumerate(start_idx):\n",
    "            iRow, iCol = np.unravel_index(i+plot_offset, (nRow, nCol))\n",
    "\n",
    "            # plot ground Truth\n",
    "            ax[iRow, iCol].scatter(x[si, :, 0], x[si, :, 1], c=cmap(\n",
    "                colors[si:si+wSize]), marker='o')\n",
    "            ax[iRow, iCol].plot(x[si, :, 0], x[si, :, 1], 'k', alpha=0.5)\n",
    "            ax[iRow, iCol].axis('equal')\n",
    "\n",
    "            # plot reconstructed\n",
    "            ax[iRow, iCol].plot(y[si, 0, 0], y[si, 0, 1],\n",
    "                                'ro', mfc='none', markersize=10)\n",
    "            ax[iRow, iCol].plot(y[si, :, 0], y[si, :, 1],\n",
    "                                color='red', alpha=0.5)\n",
    "            ax[iRow, iCol].plot(y[si, :, 0], y[si, :, 1],\n",
    "                                '.', color='red', alpha=0.5)\n",
    "            ax[iRow, iCol].axis('equal')\n",
    "            ax[iRow, iCol].set_title(f'{si/60:.1f}s~{(si+wSize)/60:.1f}s')\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "    @staticmethod\n",
    "    def traj_and_Reconstruc_from_trial(df, trialno, model, wSize=30, **kwargs):\n",
    "        '''\n",
    "        Second order function for plotting trajectory and reconstructed trajectory\n",
    "        Model is run at this level to get the reconstructed trajectory\n",
    "        '''\n",
    "        # extract data\n",
    "        df = df.query(f'trialno == {trialno}')\n",
    "        x = DataProcessing.rollingWindow_from_df(df, wSize, 1)\n",
    "\n",
    "        # run reconstruction\n",
    "        model.eval()\n",
    "        x_ = torch.from_numpy(x).double()\n",
    "        y = model(x_).detach().cpu().numpy()\n",
    "\n",
    "        # cumsum\n",
    "        x_cum = x.cumsum(axis=1)\n",
    "        y_cum = y.cumsum(axis=1)\n",
    "        x_full = df[['x-shift', 'y-shift']].values\n",
    "        x_full = x_full.cumsum(axis=0)\n",
    "\n",
    "        return Plot.traj_and_Reconstruc_from_batch(x_cum, y_cum, x_full=x_full, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def traj_and_Reconstruc_quick_check(subj, task, trialno, path='TrajNet_train', model_type='val', **kwargs):\n",
    "        '''Third order function for plotting trajectory and reconstructed trajectory\n",
    "        '''\n",
    "        # load data\n",
    "        df = LoadData.mouseMovement(subj, task)\n",
    "\n",
    "        # load model\n",
    "        model = Model.load(subj=subj, task=task, path=path,\n",
    "                           model_type=model_type)\n",
    "        return Plot.traj_and_Reconstruc_from_trial(df, trialno=trialno, model=model, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def traj_and_Reconstruc(x, y, ax, legend=True):\n",
    "        \"\"\" plot trajectory and reconstructed trajectory simple version \n",
    "        Args:\n",
    "            x: Ground true trajectory\n",
    "            y: Reconstructed\n",
    "            ax: matplotlib axis\n",
    "        \"\"\"\n",
    "\n",
    "        x = np.vstack([np.zeros((1, 2)), x])\n",
    "        y = np.vstack([np.zeros((1, 2)), y])\n",
    "        ax.plot(x[:, 0], x[:, 1], '-')\n",
    "        ax.plot(y[:, 0], y[:, 1], '-')\n",
    "        ax.plot(0, 0, 'or')\n",
    "        ax.axis('equal')\n",
    "        if legend:\n",
    "            ax.legend(['Ground true trajectory', 'Reconstructed trajectory', 'orig'],\n",
    "                      bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    @staticmethod\n",
    "    def load(subj='K-Reg-S-18', task='one_dot', model_type='val', path='TrajNet_train_onUse'):\n",
    "        ''' Load model from checkpoint\n",
    "        '''\n",
    "        import TrajNet_train\n",
    "        model = TrajNet_train.PL_model()\n",
    "        path_cp = path_data / path / f'{subj}_{task}_{model_type}.ckpt'\n",
    "        model = model.load_from_checkpoint(path_cp).double().eval()\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def quick_forward(subj, x):\n",
    "        ''' passing x to subj's model\n",
    "        x can be a list of numpy array or a numpy array\n",
    "        '''\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = Model.load(subj).to(device)\n",
    "        isList = type(x) is list\n",
    "        if not isList:\n",
    "            x = [x]            \n",
    "        h = []\n",
    "        y = []\n",
    "        for x_ in x:\n",
    "            x_ = torch.from_numpy(x_).double().to(device)\n",
    "            y_ = model.forward(x_)\n",
    "            h_ = model.model.x_hidden\n",
    "            y.append(y_.detach().cpu().numpy())\n",
    "            h.append(h_.detach().cpu().numpy())   \n",
    "        if not isList:\n",
    "            y = y[0] \n",
    "            h = h[0]\n",
    "        return h, y    \n",
    "\n",
    "\n",
    "class Analysis:\n",
    "    @staticmethod\n",
    "    def fit_function(x, y, fun=expon, plot=False):\n",
    "        from scipy.optimize import curve_fit\n",
    "        para = curve_fit(fun, x, y, 0.5)\n",
    "        if plot:\n",
    "            plt.plot(x, fun(x, *para[0]))\n",
    "            plt.plot(x, y)\n",
    "        return para\n",
    "\n",
    "    @staticmethod\n",
    "    def pca(x, n_components=None, normalise=True, plot_explained_variance=False):\n",
    "        from sklearn.decomposition import PCA\n",
    "        if normalise:\n",
    "            from sklearn.preprocessing import scale\n",
    "            x = scale(x, axis=0)\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(x)\n",
    "        if plot_explained_variance:\n",
    "            n = len(pca.explained_variance_ratio_)\n",
    "            plt.bar(range(n), pca.explained_variance_ratio_.cumsum())\n",
    "            plt.xlabel('Number of components')\n",
    "            plt.ylabel('Cumulative explained variance')\n",
    "            plt.show()\n",
    "        return pca\n",
    "\n",
    "    @staticmethod\n",
    "    def dim_measure(x):\n",
    "        # perform PCA and fit exponential distribution to explained_variance_ratio_\n",
    "        pca = Analysis.pca(x)\n",
    "        y = pca.explained_variance_ratio_\n",
    "        x = np.arange(len(y))\n",
    "        return Analysis.fit_function(x, y)[0][0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def auc_oneVsOthers(x):\n",
    "        ''' compute AUC for one vs others\n",
    "        x: sample x class \n",
    "        '''\n",
    "        from sklearn import metrics \n",
    "        auc = []\n",
    "        for i in range(x.shape[1]):\n",
    "            y_true = np.zeros(x.shape)\n",
    "            y_true[:, i] = 1\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y_true.flatten(), -x.flatten())\n",
    "            auc.append(metrics.auc(fpr, tpr))\n",
    "        return np.hstack(auc)    \n",
    "    \n",
    "    @staticmethod\n",
    "    def argmin_ratio(x):\n",
    "        ''' the ratio of the class with minimal value at each sample point\n",
    "        x: sample x class \n",
    "        '''\n",
    "        iMin = x.argmin(axis=1)\n",
    "        unique, counts = np.unique(iMin, return_counts=True)\n",
    "        b = np.zeros(3)\n",
    "        for i, j in zip(unique, counts):\n",
    "            b[i] = j\n",
    "        return b / x.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def class_in_topN(dist_timeSeries):\n",
    "        n, nc = dist_timeSeries.shape\n",
    "        labels = np.ones_like(dist_timeSeries) * np.arange(nc)\n",
    "        topN = np.argsort(dist_timeSeries.flatten())[0:n]\n",
    "        topN = labels.flatten()[topN]\n",
    "        ratio = [np.sum(topN == i) / n  for i in range(nc)]\n",
    "        return ratio\n",
    "\n",
    "    @staticmethod\n",
    "    def rsa(X, dist_measure='euclidean'):\n",
    "        '''\n",
    "        X: list of numpy arrays. \n",
    "        X[i] i is subjects.\n",
    "        X[i] is a 2D array samples x fetures\n",
    "        First, we calculate distance matrix between each pair of samples for each subject\n",
    "        Then, we compute the similarity of the distance matrix between each subjects\n",
    "        Finally, return the similarity matrix\n",
    "        '''\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        dist_mat = [pairwise_distances(x, metric=dist_measure).flatten() for x in X]\n",
    "        dist_mat = np.vstack(dist_mat)\n",
    "        return np.corrcoef(dist_mat)    \n",
    "\n",
    "class GroupOperation:\n",
    "\n",
    "    @staticmethod\n",
    "    def map(fun, subjs, *args, **kwargs):\n",
    "        data = []\n",
    "        with alive_bar(len(subjs), force_tty=True, title='Group loop') as bar:\n",
    "            for i, subj in enumerate(subjs):\n",
    "                data.append(fun(subj, *args, **kwargs))\n",
    "                bar()\n",
    "        return data\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def map_trial(fun, trials):\n",
    "        ''' run trial loop for funtion with iTrial as input\n",
    "        trials: list of trial numbers\n",
    "        '''\n",
    "        data = []\n",
    "        # with alive_bar(len(trials), force_tty=True, title='Trial loop') as bar:\n",
    "        for trial in trials:\n",
    "            data.append(fun(trial))\n",
    "            # bar()\n",
    "        return data\n",
    "\n",
    "class test:\n",
    "    @staticmethod\n",
    "    def quick_forward(subj, x):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = Model.load(subj).to(device)\n",
    "        if type(x) is not list:\n",
    "            x = [x]\n",
    "            \n",
    "        h = []\n",
    "        y = []\n",
    "        for x_ in x:\n",
    "            x_ = torch.from_numpy(x_).double().to(device)\n",
    "            y_ = model.forward(x_)\n",
    "            h_ = model.model.x_hidden\n",
    "            y.append(y_.detach().cpu().numpy())\n",
    "            h.append(h_.detach().cpu().numpy())    \n",
    "        if type(x) is not list:\n",
    "            y = y[0] \n",
    "            h = h[0]\n",
    "        return h, y\n",
    "\n",
    "\n",
    "class Save:\n",
    "    @staticmethod\n",
    "    def savepath(folder, filename):\n",
    "        pathname = path_data / folder\n",
    "        pathname.mkdir(parents=True, exist_ok=True)\n",
    "        return str(pathname / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
